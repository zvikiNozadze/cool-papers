# Cool Papers
### List of wonderful papers I found interesting, I'll keep on adding.
### Distributed Systems
* [MapReduce: Simplified Data Processing on Large Clusters](https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf)
### Operating Systems and System Software
* [On-the-Fly Garbage Collection: An Exercise in Cooperation](https://lamport.azurewebsites.net/pubs/garbage.pdf)
### machine learning
* [Unsupervised Translation of Programming Languages](https://arxiv.org/pdf/2006.03511.pdf)
* [Fixup Initialization: Residual Learning Without Normalization](https://arxiv.org/abs/1901.09321)
* [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186)
* [Visualizing the Loss Landscape of Neural Nets](https://arxiv.org/abs/1712.09913)
* [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)
* [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)
* [Forecasting economic and financial time series: ARIMA VS LSTM](https://arxiv.org/ftp/arxiv/papers/1803/1803.06386.pdf)
* [A robust functional time series forecasting method](https://arxiv.org/pdf/1901.06030.pdf)
* [Robust and Adaptive Online Time Series Prediction with LSTM](http://downloads.hindawi.com/journals/cin/2017/9478952.pdf)
* [A systematic study of the class imbalance problem in convolutional neural networks](https://arxiv.org/abs/1710.05381)
* [The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation](https://arxiv.org/abs/1611.09326)
* [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)
* [Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/abs/1801.06146)
* [On the difficulty of training Recurrent Neural Networks](https://arxiv.org/pdf/1211.5063.pdf)
* [Learning Long-Term Dependencies with Gradient Descent is Difficult](http://ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf)
* [Highway Networks](https://arxiv.org/abs/1505.00387)
* [Neural Ordinary Differential Equations](https://arxiv.org/abs/1806.07366)
* [Hierarchical Graph Pooling with Structure Learning](https://arxiv.org/abs/1911.05954)
* [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)
* [Fixup Initialization: Residual Learning Without Normalization](https://arxiv.org/abs/1901.09321)
* [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155)
* [PyTorch: An Imperative Style, High-Performance Deep Learning Library](https://arxiv.org/abs/1912.01703?fbclid=IwAR2RnDjn9WBu8SwOgezv6-IgTvI4wINJibWhDTI5wozZjVYxGdF6--iNuHo)
* [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a.html)
* [StyleGAN2 Distillation for Feed-forward Image Manipulation](https://arxiv.org/abs/2003.03581?fbclid=IwAR0VVA6eE8Vzj59_m9sAQLX01d_KV2JAPF97gtxHSkf-DsyHvznMCuwPrIs)
* [KALE: When Energy-Based Learning Meets Adversarial Training](https://arxiv.org/pdf/2003.05033.pdf)
